name: FDA ETL Pipeline   #test

on:
  push:
    branches: ["dev"]
    paths:
      - "etl/**"
      - "db/**"
      - "requirements.txt"
  pull_request:
    branches: ["dev"]
    paths:
      - "etl/**"
      - "db/**"
      - "requirements.txt"

jobs:
  etl-demo:
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run ETL pipeline for demo
        run: python -m etl.pipeline --demo-q1
        env:
          RUN_SNOWFLAKE_LOAD: 1  # Demo mode: skip Snowflake
          SNOW_USER: ${{ secrets.SNOW_USER }}
          SNOW_PASSWORD: ${{ secrets.SNOW_PASSWORD }}
          SNOW_ACCOUNT: ${{ secrets.SNOW_ACCOUNT }}
          SNOW_WAREHOUSE: ${{ secrets.SNOW_WAREHOUSE }}
          TMPDIR: /tmp  # ETL writes to /tmp

      - name: List processed CSVs
        run: ls -lh /tmp/data/processed/*.csv || echo "No processed files found"

      - name: Upload raw FAERS files
        uses: actions/upload-artifact@v4
        with:
          name: faers-txt
          path: /tmp/data/raw/*.txt

      - name: Upload merged CSVs
        uses: actions/upload-artifact@v4
        with:
          name: faers-processed
          path: /tmp/data/processed/*.csv
